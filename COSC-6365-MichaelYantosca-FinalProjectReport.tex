\documentclass{article}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage[utf8]{luainputenc}
\usepackage[bibencoding=utf8,backend=biber]{biblatex}
\addbibresource{COSC-6365-MichaelYantosca-FinalProjectReport.bib}
\pagestyle{fancy}
\fancyhf{}
\rhead{COSC-6365 Final Project Proposal}
\lhead{Michael Yantosca}
\rfoot{\thepage}

\begin{document}
\begin{section}{Abstract}
  To explore the relative merits between single-node computer power in depth versus multi-node compute power in breadth,
  I propose an experiment comparing the performance and efficiency of Cannon's algorithm\autocites{Lecture17Slides,GuptaSadayappan} for the matrix multiplication
  problem $C = A \times B$ between a single-node OpenMP implementation utilizing accelerators and a multi-node MPI
  implementation spread across a cluster.
  \begin{subsection}{Data}
    For the sake of time, I will only consider the $C$-stationary case for a limited number of matrix sizes
    (256x256, 1024x1024, 4096x4096, 16384x16384, 256x1024, 256x4096, 256x16384, 16384x256, 16384x256, 4096x256, 1024x256).
    The matrices will be filled with random numbers for the performance trials. Validation trials will be made
    through specially devised matrices $A$ and $B$ such that each cell of the product matrix $C$ will have a unique value.
  \end{subsection}
  \begin{subsection}{Resources}
    The OpenMP trials will be executed on the GPU nodes on BRIDGES\footnote{If the GPU nodes on BRIDGES do not support
    OpenMP offloading to the P100 and K80 GPUs, the acceleration will be done via OpenACC, or, as a last resort, CUDA.}
    and/or the KNL nodes on STAMPEDE2, whereas the MPI trials will be executed on the appropriate non-accelerated nodes
    on BRIDGES.
  \end{subsection}
  \begin{subsection}{Efficiency}
    The efficiency of the MPI trials will be gauged against a strong-scaling roofline model based on the physical
    characteristics of a single non-GPU node on BRIDGES. The processor in this case is the 28-core, 2.30 GHz Intel E5-2695,
    which is theoretically capable of 2.30 GHz * 28 cores * 4 SIMD instructions/cycle (AVX256) = 257.6 GFLOPs/s/node.
    \begin{paragraph}{}
      The efficiency of the OpenMP trials will be gauged against a roofline model based on the physical characteristics of the accelerator.
      The NVIDIA P100 is theoretically capable of 9.3 SP TFLOPs/s/card\autocite{P100Datasheet}, whereas the NVIDIA K80 is theoretically capable of
      8.74 TFLOPs/s/card\autocite{AnandtechK80}. In the event that KNL nodes on STAMPEDE2 are utilized, the theoretical roofline will
      be considered as 1.4 GHz * 68 cores * 8 SIMD instructions/cycle (AVX512) = 761.6 GFLOPs/s/node\autocite{Stampede2UserGuide}\footnote{While KNL supports 4 threads/core, only 1 is considered here as performance may degrade over shared resources.}.
    \end{paragraph}
    \begin{paragraph}{}
      The matrix multiplication functions provided with the Intel Math Kernel Library (MKL) will be consulted as a reference for empirically
      achievable single-node performance either without GPU acceleration or in the case of KNL nodes while the matrix multiplication sample provided
      by the CUDA toolkit utilizing CUBLAS functions will be consulted as a reference for empirically achievable single-node performance
      with GPU acceleration.
    \end{paragraph}
  \end{subsection}
  \begin{subsection}{Hypotheses}
    I predict that the accelerated OpenMP solution will outperform the MPI solution for smaller matrix sizes until
    reaching an inflection point where the contention between resources within the node is a greater bottleneck than
    the communication overhead across multiple nodes. This inflection point will largely depend on the architecture
    and layout of the accelerator used, i.e., the dimensions of the various hierarchical groupings of its compute resources.
  \end{subsection}
\end{section}

\begin{section}{Validation}
  \begin{paragraph}{}
    Before commencing on the actual implementation of the matrix multiplication programs, it was determined that the design of
    the validation trials would take first priority so as to catch errors in implementation earlier rather than later.
    The validation mechanism itself needed to operate under several exacting constraints. It has been already mentioned
    that the product matrix $C$ in validation mode would need to house a unique value in each cell once calculations had finished.
    This was to ensure that every dot product of each row in $A$ and each column in $B$ did not suffer corruption from any other
    dot products or other implementation errors by providing a quick reference that could be used as a sanity check.
  \end{paragraph}
  \begin{paragraph}{}
    Alacrity in the validation implementation was key. If the validation required additional extended calculations to replicate the results serially,
    the time to find and correct errors could become prohibitively slow, especially as the matrix dimensions $M$ and $N$ increased.
    Ideally, the validation would be a constant time function $f$ based on the row and column index of the cell in question, i.e.,
    $C_{i,j} = f(i,j)$.
  \end{paragraph}
  \begin{paragraph}{}
    The under-the-hood 1D row-major ordering and indexing of 2D matrices in the C programming language provided the requisite inspiration.
    The cell of every 2D matrix in C is accessed implicitly by the following formula: $i \times N +j$, where $i$ is the row index,
    $j$ is the column index, and $N$ is the number of columns\autocite[][113]{KnR}. Initial attempts sough to find some function $f(i,j) = \displaystyle\sum_{k=1}^{N} A_{i,k} \cdot B_{k,j}$
    such that the matrix $A$ independently provided the $i$ component while the matrix $B$ independently provided the $j$ component.
  \end{paragraph}
  \begin{paragraph}{}
    After wrestling with the algebra for some time, a simple solution was devised. One merely had to populate each cell of the matrix $A$
    with its row index $i$, each cell of the matrix $B$ with the constant $1$, and each cell of the matrix $C$ with its column index $j$
    instead of the customary constant $0$. In this way, the equation $C = A \times B$ became $C = A \times B + C_{0}$ where
    performance trials would start with $C_{0} = \textbf{0}$ and validation trials would start with $C_{0} = \textbf{J}$.
  \end{paragraph}
 \end{section}

\printbibliography

\end{document}
