\documentclass{article}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage[utf8]{luainputenc}
\usepackage[bibencoding=utf8,backend=biber]{biblatex}
\addbibresource{COSC-6365-MichaelYantosca-FinalProjectReport.bib}
\pagestyle{fancy}
\fancyhf{}
\rhead{COSC-6365 Final Project Proposal}
\lhead{Michael Yantosca}
\rfoot{\thepage}

\begin{document}
\begin{section}{Abstract}
  To explore the relative merits between single-node computer power in depth versus multi-node compute power in breadth,
  I propose an experiment comparing the performance and efficiency of Cannon's algorithm\autocites{Lecture17Slides,GuptaSadayappan} for the matrix multiplication
  problem $C = A \times B$ between a single-node OpenMP implementation utilizing accelerators and a multi-node MPI
  implementation spread across a cluster.
  \begin{subsection}{Data}
    For the sake of time, I will only consider the $C$-stationary case for a limited number of matrix sizes
    (256x256, 1024x1024, 4096x4096, 16384x16384, 256x1024, 256x4096, 256x16384, 16384x256, 16384x256, 4096x256, 1024x256).
    The matrices will be filled with random numbers for the performance trials. Validation trials will be made
    through specially devised matrices $A$ and $B$ such that each cell of the product matrix $C$ will have a unique value.
  \end{subsection}
  \begin{subsection}{Resources}
    The OpenMP trials will be executed on the GPU nodes on BRIDGES\footnote{If the GPU nodes on BRIDGES do not support
    OpenMP offloading to the P100 and K80 GPUs, the acceleration will be done via OpenACC, or, as a last resort, CUDA.}
    and/or the KNL nodes on STAMPEDE2, whereas the MPI trials will be executed on the appropriate non-accelerated nodes
    on BRIDGES.
  \end{subsection}
  \begin{subsection}{Efficiency}
    The efficiency of the MPI trials will be gauged against a strong-scaling roofline model based on the physical
    characteristics of a single non-GPU node on BRIDGES. The processor in this case is the 28-core, 2.30 GHz Intel E5-2695,
    which is theoretically capable of 2.30 GHz * 28 cores * 4 SIMD instructions/cycle (AVX256) = 257.6 GFLOPs/s/node.
    \begin{paragraph}{}
      The efficiency of the OpenMP trials will be gauged against a roofline model based on the physical characteristics of the accelerator.
      The NVIDIA P100 is theoretically capable of 9.3 SP TFLOPs/s/card\autocite{P100Datasheet}, whereas the NVIDIA K80 is theoretically capable of
      8.74 TFLOPs/s/card\autocite{AnandtechK80}. In the event that KNL nodes on STAMPEDE2 are utilized, the theoretical roofline will
      be considered as 1.4 GHz * 68 cores * 8 SIMD instructions/cycle (AVX512) = 761.6 GFLOPs/s/node\autocite{Stampede2UserGuide}\footnote{While KNL supports 4 threads/core, only 1 is considered here as performance may degrade over shared resources.}.
    \end{paragraph}
    \begin{paragraph}{}
      The matrix multiplication functions provided with the Intel Math Kernel Library (MKL) will be consulted as a reference for empirically
      achievable single-node performance either without GPU acceleration or in the case of KNL nodes while the matrix multiplication sample provided
      by the CUDA toolkit utilizing CUBLAS functions will be consulted as a reference for empirically achievable single-node performance
      with GPU acceleration.
    \end{paragraph}
  \end{subsection}
  \begin{subsection}{Hypotheses}
    I predict that the accelerated OpenMP solution will outperform the MPI solution for smaller matrix sizes until
    reaching an inflection point where the contention between resources within the node is a greater bottleneck than
    the communication overhead across multiple nodes. This inflection point will largely depend on the architecture
    and layout of the accelerator used, i.e., the dimensions of the various hierarchical groupings of its compute resources.
  \end{subsection}
\end{section}

\begin{section}{Validation}
  \begin{paragraph}{}
    Before commencing on the actual implementation of the matrix multiplication programs, it was determined that the design of
    the validation trials would take first priority so as to catch errors in implementation earlier rather than later.
    The validation mechanism itself needed to operate under several exacting constraints. It has been already mentioned
    that the $m \times n$ product matrix $C$ in validation mode would need to house a unique value in each cell once calculations had finished.
    This was to ensure that every dot product of each row in $m \times q$ matrix $A$ and each column in $q \times n$ matrix $B$ did not suffer corruption
    from any other dot products or other implementation errors by providing a quick reference that could be used as a sanity check.
  \end{paragraph}
  \begin{paragraph}{}
    Alacrity in the validation implementation was key. If the validation required additional extended calculations to replicate the results serially,
    the time to find and correct errors could become prohibitively slow, especially as the matrix dimensions $m$, $q$, and $n$ increased.
    Ideally, the validation would be a constant time function $f$ based on the row and column index of the cell in question, i.e.,
    $C_{i,j} = f(i,j)$.
  \end{paragraph}
  \begin{paragraph}{}
    The under-the-hood 1D row-major ordering and indexing of 2D matrices in the C programming language provided the requisite inspiration.
    The cell of every 2D matrix in C is accessed implicitly by the following formula: $iq +j$, where $i$ is the row index,
    $j$ is the column index, and $n$ is the number of columns\autocite[][113]{KnR}. Initial attempts sough to find some function $f(i,j) = \displaystyle\sum_{k=1}^{N} A_{i,k} \cdot B_{k,j}$
    such that the matrix $A$ independently provided the $i$ component while the matrix $B$ independently provided the $j$ component.
  \end{paragraph}
  \begin{paragraph}{}
    After wrestling with the algebra for some time, a simpler solution was devised. Each cell of the matrix $A$
    would be populated with its row index $i$. Each cell of the matrix $B$ would be populated with the constant $1$.
    Each cell of the product matrix $C$ would be pre-populated with its column index $j$ instead of the customary constant $0$.
    In this way, the equation $C = A \times B$ became $C = A \times B + C_{0}$ where performance trials would start with
    $C_{0} = \textbf{0}$ and validation trials would start with $C_{0} = [\textbf{0}\ \textbf{1}\ \ldots\ \textbf{m}]$.
  \end{paragraph}
  \begin{paragraph}{}
    While this satisfies the desired formula $in + j$ per cell, it does not provide a checksum against column drift
    since $B$ is simply a homogeneous field of ones. The basic principle could be improved as follows. Let each cell of the matrix
    $A$ be populated with the value $i + 1$. Let each cell of the matrix $B$ be populated with the value $j$. If a basis
    of $C_{0}$ = \textbf{0} is assumed, each cell of the product matrix $C$ will contain the value $q(i + 1)j$, which expands to
    $qij + qj$. By setting the basis matrix $C_{0}$ so that each cell contains $-((q-1)j + (j-1)iq)$ , each cell of the product matrix $C$
    will then contain the desired value $iq + j$. This is a relatively safe method for obtaining the desired value since there are no
    division operations required.
  \end{paragraph}
  \begin{paragraph}{}
    The problem with this latest refinement and even all the previous refinements is that the resultant values did not fit within the range of precise integral
    values available in single-precision floating point, i.e., [$-2^{24}$,$2^{24}$]\autocite{SPIntLimit}, given the target matrix sizes. The validation
    method needed to be able to precisely support values as high as $16383 \times 16383 + 16382 \times 16383 \times 16384$, or something on the order
    of $2^{42}$. Several attempts to compress the range by reducing $i$ and $j$ failed to produce the desired results and only complicated the requisite
    basis matrix $C_{0}$ with no guarantee of precision fidelity.
  \end{paragraph}
  \begin{paragraph}{}
    Furthermore, the previous equation made an untenable assumption in view of the proposed target matrix sizes. The inner dimension $q$ is not
    necessarily equal to the final column dimension $n$ of the matrix $C$. Such an invariant only holds if the matrices $A$ and $B$ are square.
  \end{paragraph}
 \end{section}

\printbibliography

\end{document}
